"""
Flask Backend Server for Keywords Checker
Provides API endpoints for product copy checking with Excel support
"""

import os
import io
import logging
from pathlib import Path
from datetime import datetime
from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
from dotenv import load_dotenv
import litellm
import pandas as pd
from skill_manager import SkillManager
from s3_manager import S3Manager
from redis_cache_manager import RedisCacheManager

# Load environment variables
load_dotenv()

# Configure logging
log_dir = Path(__file__).parent / "logs"
log_dir.mkdir(exist_ok=True)

log_filename = log_dir / f"app_{datetime.now().strftime('%Y%m%d')}.log"

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_filename, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)
logger.info("=" * 60)
logger.info("Keywords Checker Backend Server Starting...")
logger.info(f"Log file: {log_filename}")
logger.info("=" * 60)

# Initialize Flask app
app = Flask(__name__, static_folder='../frontend', static_url_path='')

# Serve frontend
@app.route('/')
def serve_frontend():
    """Serve the frontend index.html"""
    return app.send_static_file('index.html')

CORS(app, resources={
    r"/api/*": {
        "origins": ["http://localhost:8080", "http://127.0.0.1:8080"],
        "methods": ["GET", "POST", "OPTIONS"],
        "allow_headers": ["Content-Type"]
    }
})

# Configure LiteLLM
os.environ["OPENAI_API_KEY"] = os.getenv('OPENAI_API_KEY', 'sk-xxxxxx')
LITELLM_API_BASE = os.getenv('LITELLM_API_BASE', 'https://askul-gpt.askul-it.com/v1')
LITELLM_MODEL = os.getenv('LITELLM_MODEL', 'gpt-5-mini')

# LiteLLMã®ãƒªãƒˆãƒ©ã‚¤è¨­å®šï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒªãƒˆãƒ©ã‚¤å›æ•°ã‚’åˆ¶é™ï¼‰
litellm.num_retries = 2  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ3å›ã‹ã‚‰2å›ã«æ¸›ã‚‰ã™
litellm.request_timeout = 120  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’120ç§’ã«è¨­å®š

# Initialize Skill Manager
SKILLS_DIR = Path(__file__).parent / "skills"
skill_manager = SkillManager(SKILLS_DIR)
skill_manager.load_all_skills()

# Initialize S3 Manager (optional, only if bucket names are set)
s3_manager = None
if os.getenv('EXCEL_BUCKET_NAME') or os.getenv('S3_BUCKET_NAME'):
    try:
        s3_manager = S3Manager()
        logger.info(f"S3 Manager initialized - Excel: {os.getenv('EXCEL_BUCKET_NAME')}, Skills: {os.getenv('SKILLS_BUCKET_NAME')}")
    except Exception as e:
        logger.warning(f"S3 Manager initialization failed: {e}")

# Initialize Redis Cache Manager
redis_cache = None
if os.getenv('REDIS_HOST'):
    try:
        redis_cache = RedisCacheManager(ttl=86400)  # 24 hour TTL for skills
        logger.info(f"Redis Cache Manager initialized: {os.getenv('REDIS_HOST')}:{os.getenv('REDIS_PORT', 6379)}")
    except Exception as e:
        logger.warning(f"Redis Cache Manager initialization failed: {e}")


def get_skill_file_with_cache(file_key):
    """
    Get skill file from cache or S3
    
    Args:
        file_key: S3 key for skill file
        
    Returns:
        str: File content or None
    """
    # Try cache first
    if redis_cache:
        cached_content = redis_cache.get_skill_file(file_key)
        if cached_content:
            logger.debug(f"Skill file from cache: {file_key}")
            return cached_content
    
    # Load from S3
    if s3_manager and s3_manager.skills_bucket_name:
        try:
            content = s3_manager.get_skill_file(file_key)
            
            # Store in cache
            if redis_cache and content:
                redis_cache.set_skill_file(file_key, content)
            
            return content
            
        except Exception as e:
            logger.error(f"Error loading skill file from S3: {e}")
            return None
    
    # Fallback to local file
    local_path = SKILLS_DIR / file_key
    if local_path.exists():
        logger.debug(f"Skill file from local: {file_key}")
        return local_path.read_text(encoding='utf-8')
    
    return None


def build_product_message(row):
    """
    Build a product message from Excel row data
    
    Args:
        row: Pandas Series containing product data
        
    Returns:
        Tuple: (product_message, has_check_data)
        - product_message: String containing formatted product information
        - has_check_data: Boolean indicating if there's data to check (other than product name)
    """
    # ãƒã‚§ãƒƒã‚¯å¯¾è±¡åˆ—ï¼ˆå•†å“åä»¥å¤–ï¼‰
    check_columns = [
        '*å¤‰æ›´å‰_å•†å“ã®ç‰¹å¾´BtoB',
        '*å¤‰æ›´å‰_MDãŠã™ã™ã‚ã‚³ãƒ¡ãƒ³ãƒˆBtoB',
        '*å¤‰æ›´å‰_çŸ­ã„ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼BtoB',
        '*å¤‰æ›´å‰_ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼BtoC',
        '*å¤‰æ›´å‰_å•†å“ã®ç‰¹å¾´BtoC'
    ]
    
    message_parts = []
    has_check_data = False
    
    # å•†å“åã‚’æœ€åˆã«è¿½åŠ 
    if '*å•†å“å' in row and pd.notna(row['*å•†å“å']) and row['*å•†å“å'] != '':
        message_parts.append(f"å•†å“å: {row['*å•†å“å']}")
    
    # ãƒã‚§ãƒƒã‚¯å¯¾è±¡åˆ—ã‚’è¿½åŠ 
    for column in check_columns:
        if column in row and pd.notna(row[column]) and row[column] != '':
            message_parts.append(f"{column}: {row[column]}")
            has_check_data = True
    
    return "\n".join(message_parts), has_check_data


def extract_conclusion(result_text):
    """
    Extract OK/NG conclusion from LLM result
    
    Args:
        result_text: Text result from LLM
        
    Returns:
        "OK" or "NG" or "UNKNOWN"
    """
    # Look for conclusion pattern in the result
    lines = result_text.split('\n')
    for line in lines:
        if 'çµè«–' in line:
            # Check the next few lines for OK or NG
            idx = lines.index(line)
            for i in range(idx, min(idx + 5, len(lines))):
                if 'NG' in lines[i]:
                    return "NG"
                elif 'OK' in lines[i]:
                    return "OK"
    
    # Fallback: search entire text
    if 'NG' in result_text:
        return "NG"
    elif 'OK' in result_text:
        return "OK"
    
    return "UNKNOWN"


@app.route('/api/health', methods=['GET'])
def health():
    """Health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'skills_loaded': len(skill_manager.skills)
    })


@app.route('/api/skills', methods=['GET'])
def list_skills():
    """List all available skills"""
    return jsonify({
        'skills': skill_manager.list_skills()
    })


@app.route('/api/check', methods=['POST'])
def check_keywords():
    """
    Check a single product for keyword violations
    
    Request JSON:
        {
            "skill_name": "å•†å“ã‚³ãƒ”ãƒ¼ãƒã‚§ãƒƒã‚¯",
            "product_info": "å•†å“å: ãƒ†ã‚¹ãƒˆå•†å“\nèª¬æ˜: ..."
        }
        
    Response JSON:
        {
            "result": "ãƒã‚§ãƒƒã‚¯çµæœ...",
            "conclusion": "OK" or "NG",
            "usage": {...}
        }
    """
    try:
        data = request.json
        skill_name = data.get('skill_name', 'å•†å“ã‚³ãƒ”ãƒ¼ãƒã‚§ãƒƒã‚¯')
        product_info = data.get('product_info', '')
        
        if not product_info:
            return jsonify({'error': 'product_info is required'}), 400
        
        # Build system prompt from skill
        system_prompt = skill_manager.build_system_prompt(skill_name)
        
        # Call LiteLLM API
        response = litellm.completion(
            model=LITELLM_MODEL,
            messages=[
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": product_info
                }
            ],
            api_base=LITELLM_API_BASE,
            max_tokens=4096,
            timeout=120  # å€‹åˆ¥APIå‘¼ã³å‡ºã—ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: 120ç§’
        )
        
        result_text = response.choices[0].message.content
        conclusion = extract_conclusion(result_text)
        
        return jsonify({
            'result': result_text,
            'conclusion': conclusion,
            'usage': {
                'input_tokens': response.usage.prompt_tokens,
                'output_tokens': response.usage.completion_tokens
            }
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/check-excel', methods=['POST'])
def check_excel():
    """
    Check multiple products from an Excel file
    
    Request:
        - file: Excel file (multipart/form-data)
        - skill_name: Skill name (optional, defaults to 'å•†å“ã‚³ãƒ”ãƒ¼ãƒã‚§ãƒƒã‚¯')
        
    Response:
        Excel file with check results
    """
    try:
        # Check if file is provided
        if 'file' not in request.files:
            return jsonify({'error': 'No file provided'}), 400
        
        file = request.files['file']
        skill_name = request.form.get('skill_name', 'å•†å“ã‚³ãƒ”ãƒ¼ãƒã‚§ãƒƒã‚¯')
        
        if file.filename == '':
            return jsonify({'error': 'No file selected'}), 400
        
        # Check file extension
        allowed_extensions = ['.xlsx', '.xls', '.xlsm']
        file_ext = os.path.splitext(file.filename)[1].lower()
        
        if file_ext not in allowed_extensions:
            return jsonify({
                'error': f'Unsupported file format: {file_ext}. Allowed formats: .xlsx, .xls, .xlsm'
            }), 400
        
        # Read Excel file - pandas will auto-detect the format
        try:
            # ã‚·ãƒ¼ãƒˆã€Œãƒã‚§ãƒƒã‚¯å¯¾è±¡ã€ã‚’èª­ã¿è¾¼ã¿ï¼ˆå…¨åˆ—ã‚’æ–‡å­—åˆ—ã¨ã—ã¦èª­ã¿è¾¼ã¿ã€å…ƒã®å‹ã‚’ä¿æŒï¼‰
            df = pd.read_excel(file, sheet_name='ãƒã‚§ãƒƒã‚¯å¯¾è±¡', dtype=str)
        except ValueError as e:
            # ã‚·ãƒ¼ãƒˆãŒå­˜åœ¨ã—ãªã„å ´åˆ
            if 'Worksheet' in str(e) or 'ãƒã‚§ãƒƒã‚¯å¯¾è±¡' in str(e):
                return jsonify({'error': 'ã‚·ãƒ¼ãƒˆã€Œãƒã‚§ãƒƒã‚¯å¯¾è±¡ã€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Excelãƒ•ã‚¡ã‚¤ãƒ«ã«ã€Œãƒã‚§ãƒƒã‚¯å¯¾è±¡ã€ã¨ã„ã†åå‰ã®ã‚·ãƒ¼ãƒˆãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚'}), 400
            raise
        except Exception as e:
            return jsonify({'error': f'Failed to read Excel file: {str(e)}'}), 400
        
        if df.empty:
            return jsonify({'error': 'Excel file is empty'}), 400
        
        # å¿…é ˆåˆ—ã®ãƒã‚§ãƒƒã‚¯
        required_columns = ['*å•†å“å']
        check_columns = [
            '*å¤‰æ›´å‰_å•†å“ã®ç‰¹å¾´BtoB',
            '*å¤‰æ›´å‰_MDãŠã™ã™ã‚ã‚³ãƒ¡ãƒ³ãƒˆBtoB',
            '*å¤‰æ›´å‰_çŸ­ã„ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼BtoB',
            '*å¤‰æ›´å‰_ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼BtoC',
            '*å¤‰æ›´å‰_å•†å“ã®ç‰¹å¾´BtoC'
        ]
        
        # å•†å“ååˆ—ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        if '*å•†å“å' not in df.columns:
            return jsonify({'error': 'ã€Œ*å•†å“åã€åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚·ãƒ¼ãƒˆã€Œãƒã‚§ãƒƒã‚¯å¯¾è±¡ã€ã«ã€Œ*å•†å“åã€åˆ—ãŒå¿…è¦ã§ã™ã€‚'}), 400
        
        # Process each row
        results = []
        conclusions = []
        total_rows = len(df)
        
        logger.info(f"ğŸ“Š Excelä¸€æ‹¬ãƒã‚§ãƒƒã‚¯é–‹å§‹: {total_rows}è¡Œ (ãƒ•ã‚¡ã‚¤ãƒ«: {file.filename})")
        
        for idx, row in df.iterrows():
            try:
                # Progress logging
                if (idx + 1) % 100 == 0 or idx == 0:
                    logger.info(f"é€²æ—: {idx + 1}/{total_rows} è¡Œå‡¦ç†ä¸­...")
                
                # Build product message from row
                product_message, has_check_data = build_product_message(row)
                
                # Skip empty rows
                if not product_message or product_message.strip() == '':
                    logger.warning(f"è¡Œ {idx + 1} ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆç©ºè¡Œï¼‰")
                    results.append("(ç©ºè¡Œ)")
                    conclusions.append("SKIPPED")
                    continue
                
                # ãƒã‚§ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„å ´åˆï¼ˆå•†å“åã®ã¿ã®å ´åˆï¼‰
                if not has_check_data:
                    logger.warning(f"è¡Œ {idx + 1} ã¯ãƒã‚§ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆå•†å“åã®ã¿ï¼‰")
                    results.append("ãƒã‚§ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ï¼ˆå•†å“åä»¥å¤–ã®åˆ—ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")
                    conclusions.append("NO_DATA")
                    continue
                
                # å•†å“ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œå‡º
                detected_keywords = skill_manager.detect_keywords(skill_name, product_message)
                
                # æ¤œå‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆreferences/*.mdãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã‚’ãƒ­ã‚°å‡ºåŠ›
                if detected_keywords:
                    logger.info(f"è¡Œ {idx + 1}: æ¤œå‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•° = {len(detected_keywords)}")
                    logger.info(f"  â†’ ä½¿ç”¨ã™ã‚‹referencesãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(sorted(detected_keywords))}")
                else:
                    logger.info(f"è¡Œ {idx + 1}: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºãªã—ï¼ˆä¸€èˆ¬çš„ãªãƒã‚§ãƒƒã‚¯ã®ã¿å®Ÿæ–½ï¼‰")
                
                # æ¤œå‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦å‹•çš„ã«system_promptã‚’æ§‹ç¯‰
                system_prompt = skill_manager.build_dynamic_system_prompt(skill_name, detected_keywords)
                
                # Call LiteLLM API
                response = litellm.completion(
                    model=LITELLM_MODEL,
                    messages=[
                        {
                            "role": "system",
                            "content": system_prompt
                        },
                        {
                            "role": "user",
                            "content": product_message
                        }
                    ],
                    api_base=LITELLM_API_BASE,
                    max_tokens=4096,
                    timeout=120  # å€‹åˆ¥APIå‘¼ã³å‡ºã—ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: 120ç§’
                )
                
                result_text = response.choices[0].message.content
                conclusion = extract_conclusion(result_text)
                
                # Log if conclusion is UNKNOWN
                if conclusion == "UNKNOWN":
                    logger.warning(f"è¡Œ {idx + 1} ã§çµè«–ãŒä¸æ˜ (UNKNOWN)")
                    logger.debug(f"å•†å“æƒ…å ±: {product_message[:100]}...")
                    logger.debug(f"LLMå¿œç­”ã®ä¸€éƒ¨: {result_text[:200]}...")
                
                results.append(result_text)
                conclusions.append(conclusion)
                
            except Exception as e:
                error_message = str(e)
                logger.error(f"è¡Œ {idx + 1} ã§ã‚¨ãƒ©ãƒ¼: {error_message}", exc_info=True)
                
                # ãƒªãƒˆãƒ©ã‚¤ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç‰¹åˆ¥ã«è¨˜éŒ²
                if 'retry' in error_message.lower() or 'timeout' in error_message.lower():
                    logger.warning(f"è¡Œ {idx + 1}: LLM APIãƒªãƒˆãƒ©ã‚¤/ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ã€‚å•†å“æƒ…å ±: {product_message[:100]}...")
                
                results.append(f"ã‚¨ãƒ©ãƒ¼: {error_message}")
                conclusions.append("ERROR")
        
        logger.info(f"âœ… å‡¦ç†å®Œäº†: {total_rows}è¡Œ")
        
        # Add results to dataframe (æ–‡å­—åˆ—å‹ã¨ã—ã¦æ˜ç¤ºçš„ã«è¨­å®š)
        df['ãƒã‚§ãƒƒã‚¯çµæœ'] = pd.Series(results, dtype=str)
        df['çµè«–'] = pd.Series(conclusions, dtype=str)
        
        # Create Excel file in memory
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='ãƒã‚§ãƒƒã‚¯çµæœ')
        
        output.seek(0)
        
        # Send file
        return send_file(
            output,
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            as_attachment=True,
            download_name='check_result.xlsx'
        )
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/check-excel-s3', methods=['POST'])
def check_excel_s3():
    """
    Check products from the latest Excel file in S3
    
    Request JSON (optional):
        {
            "skill_name": "å•†å“ã‚³ãƒ”ãƒ¼ãƒã‚§ãƒƒã‚¯",
            "file_key": "input/specific_file.xlsx"  # Optional: specify a file
        }
        
    Response JSON:
        {
            "status": "success",
            "input_file": "input/file.xlsx",
            "output_file": "output/file_checked_20260127_123456.xlsx",
            "rows_processed": 100,
            "download_url": "https://..."
        }
    """
    if not s3_manager:
        return jsonify({'error': 'S3 is not configured. Please set S3_BUCKET_NAME environment variable.'}), 503
    
    try:
        data = request.json or {}
        skill_name = data.get('skill_name', 'å•†å“ã‚³ãƒ”ãƒ¼ãƒã‚§ãƒƒã‚¯')
        specified_file_key = data.get('file_key')
        
        # Get file from S3
        if specified_file_key:
            logger.info(f"Processing specified file: {specified_file_key}")
            file_obj = s3_manager.s3_client.get_object(
                Bucket=s3_manager.bucket_name,
                Key=specified_file_key
            )
            file_stream = file_obj['Body'].read()
            file_key = specified_file_key
        else:
            logger.info("Getting latest Excel file from S3...")
            file_key, file_stream = s3_manager.get_latest_excel_file()
            
            if not file_key:
                return jsonify({'error': 'No Excel files found in S3'}), 404
        
        logger.info(f"Processing file: {file_key}")
        
        # Process Excel file (same logic as check_excel endpoint)
        # Read Excel file
        try:
            df = pd.read_excel(io.BytesIO(file_stream), sheet_name='ãƒã‚§ãƒƒã‚¯å¯¾è±¡', dtype=str)
        except ValueError as e:
            if 'Worksheet' in str(e) or 'ãƒã‚§ãƒƒã‚¯å¯¾è±¡' in str(e):
                return jsonify({'error': 'ã‚·ãƒ¼ãƒˆã€Œãƒã‚§ãƒƒã‚¯å¯¾è±¡ã€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚'}), 400
            raise
        except Exception as e:
            return jsonify({'error': f'Failed to read Excel file: {str(e)}'}), 400
        
        if df.empty:
            return jsonify({'error': 'Excel file is empty'}), 400
        
        # Check required columns
        if '*å•†å“å' not in df.columns:
            return jsonify({'error': 'ã€Œ*å•†å“åã€åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚'}), 400
        
        # Process each row (same as check_excel)
        from app import build_product_message, extract_conclusion
        
        results = []
        conclusions = []
        total_rows = len(df)
        
        logger.info(f"ğŸ“Š S3 Excelä¸€æ‹¬ãƒã‚§ãƒƒã‚¯é–‹å§‹: {total_rows}è¡Œ (ãƒ•ã‚¡ã‚¤ãƒ«: {file_key})")
        
        for idx, row in df.iterrows():
            try:
                if (idx + 1) % 100 == 0 or idx == 0:
                    logger.info(f"é€²æ—: {idx + 1}/{total_rows} è¡Œå‡¦ç†ä¸­...")
                
                product_message, has_check_data = build_product_message(row)
                
                if not product_message or product_message.strip() == '':
                    logger.warning(f"è¡Œ {idx + 1} ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆç©ºè¡Œï¼‰")
                    results.append("(ç©ºè¡Œ)")
                    conclusions.append("SKIPPED")
                    continue
                
                if not has_check_data:
                    logger.warning(f"è¡Œ {idx + 1} ã¯ãƒã‚§ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆå•†å“åã®ã¿ï¼‰")
                    results.append("ãƒã‚§ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ï¼ˆå•†å“åä»¥å¤–ã®åˆ—ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")
                    conclusions.append("NO_DATA")
                    continue
                
                detected_keywords = skill_manager.detect_keywords(skill_name, product_message)
                
                if detected_keywords:
                    logger.info(f"è¡Œ {idx + 1}: æ¤œå‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•° = {len(detected_keywords)}")
                    logger.info(f"  â†’ ä½¿ç”¨ã™ã‚‹referencesãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(sorted(detected_keywords))}")
                else:
                    logger.info(f"è¡Œ {idx + 1}: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºãªã—ï¼ˆä¸€èˆ¬çš„ãªãƒã‚§ãƒƒã‚¯ã®ã¿å®Ÿæ–½ï¼‰")
                
                system_prompt = skill_manager.build_dynamic_system_prompt(skill_name, detected_keywords)
                
                response = litellm.completion(
                    model=LITELLM_MODEL,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": product_message}
                    ],
                    api_base=LITELLM_API_BASE,
                    max_tokens=4096,
                    timeout=120
                )
                
                result_text = response.choices[0].message.content
                conclusion = extract_conclusion(result_text)
                
                if conclusion == "UNKNOWN":
                    logger.warning(f"è¡Œ {idx + 1} ã§çµè«–ãŒä¸æ˜ (UNKNOWN)")
                
                results.append(result_text)
                conclusions.append(conclusion)
                
            except Exception as e:
                error_message = str(e)
                logger.error(f"è¡Œ {idx + 1} ã§ã‚¨ãƒ©ãƒ¼: {error_message}", exc_info=True)
                results.append(f"ã‚¨ãƒ©ãƒ¼: {error_message}")
                conclusions.append("ERROR")
        
        logger.info(f"âœ… å‡¦ç†å®Œäº†: {total_rows}è¡Œ")
        
        # Add results to dataframe
        df['ãƒã‚§ãƒƒã‚¯çµæœ'] = pd.Series(results, dtype=str)
        df['çµè«–'] = pd.Series(conclusions, dtype=str)
        
        # Create Excel file in memory
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='ãƒã‚§ãƒƒã‚¯çµæœ')
        
        output.seek(0)
        file_content = output.getvalue()
        
        # Upload result to S3
        output_key = s3_manager.upload_result_file(file_content, os.path.basename(file_key))
        
        # Generate presigned URL for download
        download_url = s3_manager.get_file_url(output_key, expiration=3600)
        
        return jsonify({
            'status': 'success',
            'input_file': file_key,
            'output_file': output_key,
            'rows_processed': total_rows,
            'download_url': download_url,
            'bucket': s3_manager.bucket_name
        })
        
    except Exception as e:
        logger.error(f"S3å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
        return jsonify({'error': str(e)}), 500


@app.route('/api/s3/files', methods=['GET'])
def list_s3_files():
    """
    List all Excel files in S3 input directory
    
    Response JSON:
        {
            "files": [
                {
                    "key": "input/file.xlsx",
                    "filename": "file.xlsx",
                    "size": 12345,
                    "last_modified": "2026-01-27T12:34:56"
                }
            ]
        }
    """
    if not s3_manager:
        return jsonify({'error': 'S3 is not configured'}), 503
    
    try:
        files = s3_manager.list_input_files()
        return jsonify({'files': files})
    except Exception as e:
        logger.error(f"S3ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
        return jsonify({'error': str(e)}), 500


if __name__ == '__main__':
    # Log loaded skills
    logger.info("Loaded skills:")
    for skill in skill_manager.list_skills():
        logger.info(f"  - {skill['name']}: {skill['description']}")
    
    # Run server
    logger.info("Starting Flask server on http://0.0.0.0:5001")
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ï¼ˆç’°å¢ƒå¤‰æ•°ã§åˆ¶å¾¡ã€æœ¬ç•ªç’°å¢ƒã§ã¯Falseã«ã™ã‚‹ï¼‰
    debug_mode = os.getenv('FLASK_DEBUG', 'True').lower() == 'true'
    
    # use_reloader=Falseã«ã™ã‚‹ã¨ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´æ™‚ã®è‡ªå‹•å†èµ·å‹•ã‚’ç„¡åŠ¹åŒ–
    app.run(host='0.0.0.0', port=5001, debug=debug_mode, use_reloader=False)
