"""
Flask Backend Server for Keywords Checker
Provides API endpoints for product copy checking with Excel support
"""

import os
import io
import logging
from pathlib import Path
from datetime import datetime
from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
from dotenv import load_dotenv
import litellm
import pandas as pd
from skill_manager import SkillManager

# Load environment variables
load_dotenv()

# Configure logging
log_dir = Path(__file__).parent / "logs"
log_dir.mkdir(exist_ok=True)

log_filename = log_dir / f"app_{datetime.now().strftime('%Y%m%d')}.log"

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_filename, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)
logger.info("=" * 60)
logger.info("Keywords Checker Backend Server Starting...")
logger.info(f"Log file: {log_filename}")
logger.info("=" * 60)

# Initialize Flask app
app = Flask(__name__)
CORS(app, resources={
    r"/api/*": {
        "origins": ["http://localhost:8080", "http://127.0.0.1:8080"],
        "methods": ["GET", "POST", "OPTIONS"],
        "allow_headers": ["Content-Type"]
    }
})

# Configure LiteLLM
os.environ["OPENAI_API_KEY"] = os.getenv('OPENAI_API_KEY', 'sk-xxxxxx')
LITELLM_API_BASE = os.getenv('LITELLM_API_BASE', 'https://askul-gpt.askul-it.com/v1')
LITELLM_MODEL = os.getenv('LITELLM_MODEL', 'gpt-5-mini')

# LiteLLMã®ãƒªãƒˆãƒ©ã‚¤è¨­å®šï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒªãƒˆãƒ©ã‚¤å›æ•°ã‚’åˆ¶é™ï¼‰
litellm.num_retries = 2  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ3å›ã‹ã‚‰2å›ã«æ¸›ã‚‰ã™
litellm.request_timeout = 120  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’120ç§’ã«è¨­å®š

# Initialize Skill Manager
SKILLS_DIR = Path(__file__).parent / "skills"
skill_manager = SkillManager(SKILLS_DIR)
skill_manager.load_all_skills()


def build_product_message(row):
    """
    Build a product message from Excel row data
    
    Args:
        row: Pandas Series containing product data
        
    Returns:
        Tuple: (product_message, has_check_data)
        - product_message: String containing formatted product information
        - has_check_data: Boolean indicating if there's data to check (other than product name)
    """
    # ãƒã‚§ãƒƒã‚¯å¯¾è±¡åˆ—ï¼ˆå•†å“åä»¥å¤–ï¼‰
    check_columns = [
        '*å¤‰æ›´å‰_å•†å“ã®ç‰¹å¾´BtoB',
        '*å¤‰æ›´å‰_MDãŠã™ã™ã‚ã‚³ãƒ¡ãƒ³ãƒˆBtoB',
        '*å¤‰æ›´å‰_çŸ­ã„ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼BtoB',
        '*å¤‰æ›´å‰_ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼BtoC',
        '*å¤‰æ›´å‰_å•†å“ã®ç‰¹å¾´BtoC'
    ]
    
    message_parts = []
    has_check_data = False
    
    # å•†å“åã‚’æœ€åˆã«è¿½åŠ 
    if '*å•†å“å' in row and pd.notna(row['*å•†å“å']) and row['*å•†å“å'] != '':
        message_parts.append(f"å•†å“å: {row['*å•†å“å']}")
    
    # ãƒã‚§ãƒƒã‚¯å¯¾è±¡åˆ—ã‚’è¿½åŠ 
    for column in check_columns:
        if column in row and pd.notna(row[column]) and row[column] != '':
            message_parts.append(f"{column}: {row[column]}")
            has_check_data = True
    
    return "\n".join(message_parts), has_check_data


def extract_conclusion(result_text):
    """
    Extract OK/NG conclusion from LLM result
    
    Args:
        result_text: Text result from LLM
        
    Returns:
        "OK" or "NG" or "UNKNOWN"
    """
    # Look for conclusion pattern in the result
    lines = result_text.split('\n')
    for line in lines:
        if 'çµè«–' in line:
            # Check the next few lines for OK or NG
            idx = lines.index(line)
            for i in range(idx, min(idx + 5, len(lines))):
                if 'NG' in lines[i]:
                    return "NG"
                elif 'OK' in lines[i]:
                    return "OK"
    
    # Fallback: search entire text
    if 'NG' in result_text:
        return "NG"
    elif 'OK' in result_text:
        return "OK"
    
    return "UNKNOWN"


@app.route('/api/health', methods=['GET'])
def health():
    """Health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'skills_loaded': len(skill_manager.skills)
    })


@app.route('/api/skills', methods=['GET'])
def list_skills():
    """List all available skills"""
    return jsonify({
        'skills': skill_manager.list_skills()
    })


@app.route('/api/check', methods=['POST'])
def check_keywords():
    """
    Check a single product for keyword violations
    
    Request JSON:
        {
            "skill_name": "å•†å“ã‚³ãƒ”ãƒ¼ãƒã‚§ãƒƒã‚¯",
            "product_info": "å•†å“å: ãƒ†ã‚¹ãƒˆå•†å“\nèª¬æ˜: ..."
        }
        
    Response JSON:
        {
            "result": "ãƒã‚§ãƒƒã‚¯çµæœ...",
            "conclusion": "OK" or "NG",
            "usage": {...}
        }
    """
    try:
        data = request.json
        skill_name = data.get('skill_name', 'å•†å“ã‚³ãƒ”ãƒ¼ãƒã‚§ãƒƒã‚¯')
        product_info = data.get('product_info', '')
        
        if not product_info:
            return jsonify({'error': 'product_info is required'}), 400
        
        # Build system prompt from skill
        system_prompt = skill_manager.build_system_prompt(skill_name)
        
        # Call LiteLLM API
        response = litellm.completion(
            model=LITELLM_MODEL,
            messages=[
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": product_info
                }
            ],
            api_base=LITELLM_API_BASE,
            max_tokens=4096,
            timeout=120  # å€‹åˆ¥APIå‘¼ã³å‡ºã—ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: 120ç§’
        )
        
        result_text = response.choices[0].message.content
        conclusion = extract_conclusion(result_text)
        
        return jsonify({
            'result': result_text,
            'conclusion': conclusion,
            'usage': {
                'input_tokens': response.usage.prompt_tokens,
                'output_tokens': response.usage.completion_tokens
            }
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/check-excel', methods=['POST'])
def check_excel():
    """
    Check multiple products from an Excel file
    
    Request:
        - file: Excel file (multipart/form-data)
        - skill_name: Skill name (optional, defaults to 'å•†å“ã‚³ãƒ”ãƒ¼ãƒã‚§ãƒƒã‚¯')
        
    Response:
        Excel file with check results
    """
    try:
        # Check if file is provided
        if 'file' not in request.files:
            return jsonify({'error': 'No file provided'}), 400
        
        file = request.files['file']
        skill_name = request.form.get('skill_name', 'å•†å“ã‚³ãƒ”ãƒ¼ãƒã‚§ãƒƒã‚¯')
        
        if file.filename == '':
            return jsonify({'error': 'No file selected'}), 400
        
        # Check file extension
        allowed_extensions = ['.xlsx', '.xls', '.xlsm']
        file_ext = os.path.splitext(file.filename)[1].lower()
        
        if file_ext not in allowed_extensions:
            return jsonify({
                'error': f'Unsupported file format: {file_ext}. Allowed formats: .xlsx, .xls, .xlsm'
            }), 400
        
        # Read Excel file - pandas will auto-detect the format
        try:
            # ã‚·ãƒ¼ãƒˆã€Œãƒã‚§ãƒƒã‚¯å¯¾è±¡ã€ã‚’èª­ã¿è¾¼ã¿ï¼ˆå…¨åˆ—ã‚’æ–‡å­—åˆ—ã¨ã—ã¦èª­ã¿è¾¼ã¿ã€å…ƒã®å‹ã‚’ä¿æŒï¼‰
            df = pd.read_excel(file, sheet_name='ãƒã‚§ãƒƒã‚¯å¯¾è±¡', dtype=str)
        except ValueError as e:
            # ã‚·ãƒ¼ãƒˆãŒå­˜åœ¨ã—ãªã„å ´åˆ
            if 'Worksheet' in str(e) or 'ãƒã‚§ãƒƒã‚¯å¯¾è±¡' in str(e):
                return jsonify({'error': 'ã‚·ãƒ¼ãƒˆã€Œãƒã‚§ãƒƒã‚¯å¯¾è±¡ã€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Excelãƒ•ã‚¡ã‚¤ãƒ«ã«ã€Œãƒã‚§ãƒƒã‚¯å¯¾è±¡ã€ã¨ã„ã†åå‰ã®ã‚·ãƒ¼ãƒˆãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚'}), 400
            raise
        except Exception as e:
            return jsonify({'error': f'Failed to read Excel file: {str(e)}'}), 400
        
        if df.empty:
            return jsonify({'error': 'Excel file is empty'}), 400
        
        # å¿…é ˆåˆ—ã®ãƒã‚§ãƒƒã‚¯
        required_columns = ['*å•†å“å']
        check_columns = [
            '*å¤‰æ›´å‰_å•†å“ã®ç‰¹å¾´BtoB',
            '*å¤‰æ›´å‰_MDãŠã™ã™ã‚ã‚³ãƒ¡ãƒ³ãƒˆBtoB',
            '*å¤‰æ›´å‰_çŸ­ã„ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼BtoB',
            '*å¤‰æ›´å‰_ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼BtoC',
            '*å¤‰æ›´å‰_å•†å“ã®ç‰¹å¾´BtoC'
        ]
        
        # å•†å“ååˆ—ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        if '*å•†å“å' not in df.columns:
            return jsonify({'error': 'ã€Œ*å•†å“åã€åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚·ãƒ¼ãƒˆã€Œãƒã‚§ãƒƒã‚¯å¯¾è±¡ã€ã«ã€Œ*å•†å“åã€åˆ—ãŒå¿…è¦ã§ã™ã€‚'}), 400
        
        # Process each row
        results = []
        conclusions = []
        total_rows = len(df)
        
        logger.info(f"ğŸ“Š Excelä¸€æ‹¬ãƒã‚§ãƒƒã‚¯é–‹å§‹: {total_rows}è¡Œ (ãƒ•ã‚¡ã‚¤ãƒ«: {file.filename})")
        
        for idx, row in df.iterrows():
            try:
                # Progress logging
                if (idx + 1) % 100 == 0 or idx == 0:
                    logger.info(f"é€²æ—: {idx + 1}/{total_rows} è¡Œå‡¦ç†ä¸­...")
                
                # Build product message from row
                product_message, has_check_data = build_product_message(row)
                
                # Skip empty rows
                if not product_message or product_message.strip() == '':
                    logger.warning(f"è¡Œ {idx + 1} ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆç©ºè¡Œï¼‰")
                    results.append("(ç©ºè¡Œ)")
                    conclusions.append("SKIPPED")
                    continue
                
                # ãƒã‚§ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„å ´åˆï¼ˆå•†å“åã®ã¿ã®å ´åˆï¼‰
                if not has_check_data:
                    logger.warning(f"è¡Œ {idx + 1} ã¯ãƒã‚§ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆå•†å“åã®ã¿ï¼‰")
                    results.append("ãƒã‚§ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ï¼ˆå•†å“åä»¥å¤–ã®åˆ—ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")
                    conclusions.append("NO_DATA")
                    continue
                
                # å•†å“ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œå‡º
                detected_keywords = skill_manager.detect_keywords(skill_name, product_message)
                
                # æ¤œå‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆreferences/*.mdãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã‚’ãƒ­ã‚°å‡ºåŠ›
                if detected_keywords:
                    logger.info(f"è¡Œ {idx + 1}: æ¤œå‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•° = {len(detected_keywords)}")
                    logger.info(f"  â†’ ä½¿ç”¨ã™ã‚‹referencesãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(sorted(detected_keywords))}")
                else:
                    logger.info(f"è¡Œ {idx + 1}: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºãªã—ï¼ˆä¸€èˆ¬çš„ãªãƒã‚§ãƒƒã‚¯ã®ã¿å®Ÿæ–½ï¼‰")
                
                # æ¤œå‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦å‹•çš„ã«system_promptã‚’æ§‹ç¯‰
                system_prompt = skill_manager.build_dynamic_system_prompt(skill_name, detected_keywords)
                
                # Call LiteLLM API
                response = litellm.completion(
                    model=LITELLM_MODEL,
                    messages=[
                        {
                            "role": "system",
                            "content": system_prompt
                        },
                        {
                            "role": "user",
                            "content": product_message
                        }
                    ],
                    api_base=LITELLM_API_BASE,
                    max_tokens=4096,
                    timeout=120  # å€‹åˆ¥APIå‘¼ã³å‡ºã—ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: 120ç§’
                )
                
                result_text = response.choices[0].message.content
                conclusion = extract_conclusion(result_text)
                
                # Log if conclusion is UNKNOWN
                if conclusion == "UNKNOWN":
                    logger.warning(f"è¡Œ {idx + 1} ã§çµè«–ãŒä¸æ˜ (UNKNOWN)")
                    logger.debug(f"å•†å“æƒ…å ±: {product_message[:100]}...")
                    logger.debug(f"LLMå¿œç­”ã®ä¸€éƒ¨: {result_text[:200]}...")
                
                results.append(result_text)
                conclusions.append(conclusion)
                
            except Exception as e:
                error_message = str(e)
                logger.error(f"è¡Œ {idx + 1} ã§ã‚¨ãƒ©ãƒ¼: {error_message}", exc_info=True)
                
                # ãƒªãƒˆãƒ©ã‚¤ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç‰¹åˆ¥ã«è¨˜éŒ²
                if 'retry' in error_message.lower() or 'timeout' in error_message.lower():
                    logger.warning(f"è¡Œ {idx + 1}: LLM APIãƒªãƒˆãƒ©ã‚¤/ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ã€‚å•†å“æƒ…å ±: {product_message[:100]}...")
                
                results.append(f"ã‚¨ãƒ©ãƒ¼: {error_message}")
                conclusions.append("ERROR")
        
        logger.info(f"âœ… å‡¦ç†å®Œäº†: {total_rows}è¡Œ")
        
        # Add results to dataframe (æ–‡å­—åˆ—å‹ã¨ã—ã¦æ˜ç¤ºçš„ã«è¨­å®š)
        df['ãƒã‚§ãƒƒã‚¯çµæœ'] = pd.Series(results, dtype=str)
        df['çµè«–'] = pd.Series(conclusions, dtype=str)
        
        # Create Excel file in memory
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='ãƒã‚§ãƒƒã‚¯çµæœ')
        
        output.seek(0)
        
        # Send file
        return send_file(
            output,
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            as_attachment=True,
            download_name='check_result.xlsx'
        )
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


if __name__ == '__main__':
    # Log loaded skills
    logger.info("Loaded skills:")
    for skill in skill_manager.list_skills():
        logger.info(f"  - {skill['name']}: {skill['description']}")
    
    # Run server
    logger.info("Starting Flask server on http://0.0.0.0:5001")
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ï¼ˆç’°å¢ƒå¤‰æ•°ã§åˆ¶å¾¡ã€æœ¬ç•ªç’°å¢ƒã§ã¯Falseã«ã™ã‚‹ï¼‰
    debug_mode = os.getenv('FLASK_DEBUG', 'True').lower() == 'true'
    
    # use_reloader=Falseã«ã™ã‚‹ã¨ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´æ™‚ã®è‡ªå‹•å†èµ·å‹•ã‚’ç„¡åŠ¹åŒ–
    app.run(host='0.0.0.0', port=5001, debug=debug_mode, use_reloader=False)
